# ğŸš— æ¡ˆä¾‹ï¼šé¢„æµ‹æ±½è½¦æœˆé”€é‡ï¼ˆçº¿æ€§å›å½’ï¼‰
# åŸºäº Scikit-learn + mock æ•°æ® çš„å®Œæ•´æ¡ˆä¾‹ï¼Œç”¨æ¥é¢„æµ‹ æ–°è½¦é”€é‡ç¤ºä¾‹ã€‚

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error

# 1ï¸âƒ£ æ„é€  mock æ•°æ®
np.random.seed(42)
n_samples = 120

# æ¨¡æ‹Ÿç‰¹å¾
price = np.random.randint(100000, 400000, n_samples)        # ä»·æ ¼ï¼ˆå…ƒï¼‰
horsepower = np.random.randint(80, 250, n_samples)          # é©¬åŠ›
fuel_efficiency = np.random.uniform(5, 12, n_samples)       # æ²¹è€—ï¼ˆL/100kmï¼‰
brand_score = np.random.randint(60, 95, n_samples)          # å“ç‰Œè¯„åˆ†ï¼ˆå¸‚åœºå½±å“åŠ›ï¼‰

# æ¨¡æ‹Ÿé”€é‡ï¼ˆé”€é‡ä¸ä»·æ ¼è´Ÿç›¸å…³ï¼Œä¸é©¬åŠ›ã€å“ç‰Œæ­£ç›¸å…³ï¼‰
sales = (
    8000 
    - 0.015 * price 
    + 12 * horsepower 
    - 100 * fuel_efficiency 
    + 80 * brand_score 
    + np.random.normal(0, 800, n_samples)  # å™ªå£°
)

# ç»„è£… DataFrame
df = pd.DataFrame({
    "price": price,
    "horsepower": horsepower,
    "fuel_efficiency": fuel_efficiency,
    "brand_score": brand_score,
    "sales": sales
})

print("ğŸš˜ æ•°æ®æ ·ä¾‹ï¼š")
print(df.head())

# 2ï¸âƒ£ ç‰¹å¾ä¸ç›®æ ‡
X = df[["price", "horsepower", "fuel_efficiency", "brand_score"]]
y = df["sales"]

# 3ï¸âƒ£ æ‹†åˆ†è®­ç»ƒ / æµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4ï¸âƒ£ å»ºæ¨¡
model = LinearRegression()
model.fit(X_train, y_train)

# 5ï¸âƒ£ é¢„æµ‹ä¸è¯„ä¼°
y_pred = model.predict(X_test)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ï¼š")
print(f"RÂ²ï¼š{r2:.4f}")
print(f"MAEï¼š{mae:.2f}")

# 6ï¸âƒ£ æ¨¡å‹ç³»æ•°è§£é‡Š
print("\nâš™ï¸ æ¨¡å‹ç³»æ•°ï¼š")
coef_df = pd.DataFrame({
    "ç‰¹å¾": X.columns,
    "ç³»æ•°": model.coef_
})
print(coef_df)
print(f"æˆªè·ï¼š{model.intercept_:.2f}")

# 7ï¸âƒ£ æ•°æ®æ¢ç´¢æ€§åˆ†æ
print("\nğŸ“ˆ æ•°æ®æè¿°ç»Ÿè®¡ï¼š")
print(df.describe())

print("\nğŸ”— ç‰¹å¾ç›¸å…³æ€§åˆ†æï¼š")
correlation_matrix = df.corr()
print(correlation_matrix)

# 8ï¸âƒ£ æ•°æ®å¯è§†åŒ–
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.offline as pyo

# åˆ›å»ºç»¼åˆæ•°æ®åˆ†æå›¾è¡¨
fig = make_subplots(
    rows=2, cols=3,
    subplot_titles=('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾', 'é”€é‡åˆ†å¸ƒ', 'ä»·æ ¼ vs é”€é‡', 
                   'é©¬åŠ› vs é”€é‡', 'é¢„æµ‹å€¼ vs å®é™…å€¼', 'æ®‹å·®å›¾'),
    specs=[[{"type": "heatmap"}, {"type": "histogram"}, {"type": "scatter"}],
           [{"type": "scatter"}, {"type": "scatter"}, {"type": "scatter"}]]
)

# 1. ç›¸å…³æ€§çƒ­åŠ›å›¾
fig.add_trace(
    go.Heatmap(
        z=correlation_matrix.values,
        x=correlation_matrix.columns,
        y=correlation_matrix.columns,
        colorscale='RdBu',
        zmid=0,
        text=correlation_matrix.round(3).values,
        texttemplate="%{text}",
        textfont={"size": 10},
        showscale=True
    ),
    row=1, col=1
)

# 2. é”€é‡åˆ†å¸ƒ
fig.add_trace(
    go.Histogram(
        x=df['sales'],
        nbinsx=20,
        marker_color='skyblue',
        marker_line_color='black',
        marker_line_width=1,
        opacity=0.7,
        name='é”€é‡åˆ†å¸ƒ'
    ),
    row=1, col=2
)

# 3. ä»·æ ¼vsé”€é‡æ•£ç‚¹å›¾
fig.add_trace(
    go.Scatter(
        x=df['price'],
        y=df['sales'],
        mode='markers',
        marker=dict(color='orange', opacity=0.6),
        name='ä»·æ ¼ vs é”€é‡'
    ),
    row=1, col=3
)

# 4. é©¬åŠ›vsé”€é‡æ•£ç‚¹å›¾
fig.add_trace(
    go.Scatter(
        x=df['horsepower'],
        y=df['sales'],
        mode='markers',
        marker=dict(color='green', opacity=0.6),
        name='é©¬åŠ› vs é”€é‡'
    ),
    row=2, col=1
)

# 5. é¢„æµ‹å€¼vså®é™…å€¼
fig.add_trace(
    go.Scatter(
        x=y_test,
        y=y_pred,
        mode='markers',
        marker=dict(color='red', opacity=0.6),
        name='é¢„æµ‹å€¼ vs å®é™…å€¼'
    ),
    row=2, col=2
)

# æ·»åŠ ç†æƒ³é¢„æµ‹çº¿
min_val, max_val = y_test.min(), y_test.max()
fig.add_trace(
    go.Scatter(
        x=[min_val, max_val],
        y=[min_val, max_val],
        mode='lines',
        line=dict(color='black', dash='dash', width=2),
        name='ç†æƒ³é¢„æµ‹çº¿',
        showlegend=False
    ),
    row=2, col=2
)

# 6. æ®‹å·®å›¾
residuals = y_test - y_pred
fig.add_trace(
    go.Scatter(
        x=y_pred,
        y=residuals,
        mode='markers',
        marker=dict(color='purple', opacity=0.6),
        name='æ®‹å·®'
    ),
    row=2, col=3
)

# æ·»åŠ é›¶çº¿
fig.add_hline(y=0, line_dash="dash", line_color="black", row=2, col=3)

# æ›´æ–°å¸ƒå±€
fig.update_layout(
    title_text='ğŸš— æ±½è½¦é”€é‡é¢„æµ‹åˆ†æ',
    title_x=0.5,
    height=800,
    width=1400,
    showlegend=False
)

# æ›´æ–°xè½´å’Œyè½´æ ‡ç­¾
fig.update_xaxes(title_text="ä»·æ ¼ï¼ˆå…ƒï¼‰", row=1, col=3)
fig.update_yaxes(title_text="æœˆé”€é‡", row=1, col=3)
fig.update_xaxes(title_text="é©¬åŠ›", row=2, col=1)
fig.update_yaxes(title_text="æœˆé”€é‡", row=2, col=1)
fig.update_xaxes(title_text="å®é™…é”€é‡", row=2, col=2)
fig.update_yaxes(title_text="é¢„æµ‹é”€é‡", row=2, col=2)
fig.update_xaxes(title_text="é¢„æµ‹é”€é‡", row=2, col=3)
fig.update_yaxes(title_text="æ®‹å·®", row=2, col=3)
fig.update_xaxes(title_text="æœˆé”€é‡", row=1, col=2)
fig.update_yaxes(title_text="é¢‘æ¬¡", row=1, col=2)

# ä¿å­˜å›¾è¡¨
fig.write_html('/Users/zihao_/Documents/github/writing_log/certification/car_sales_analysis.html')
fig.write_image('/Users/zihao_/Documents/github/writing_log/certification/car_sales_analysis.png', width=1400, height=800)
fig.show()

print("\nğŸ“Š å›¾è¡¨å·²ä¿å­˜ä¸º 'car_sales_analysis.html' å’Œ 'car_sales_analysis.png'")

# 9ï¸âƒ£ å¤šæ¨¡å‹æ¯”è¾ƒ
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

print("\nğŸ¤– å¤šæ¨¡å‹æ¯”è¾ƒåˆ†æï¼š")
print("="*60)

# ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆä¸ºSVMå‡†å¤‡ï¼‰
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# å®šä¹‰å¤šä¸ªæ¨¡å‹
models = {
    'çº¿æ€§å›å½’': LinearRegression(),
    'éšæœºæ£®æ—': RandomForestRegressor(n_estimators=100, random_state=42),
    'æ¢¯åº¦æå‡': GradientBoostingRegressor(n_estimators=100, random_state=42),
    'æ”¯æŒå‘é‡æœº': SVR(kernel='rbf', C=100, gamma=0.1)
}

# æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
model_results = {}

for name, model in models.items():
    if name == 'æ”¯æŒå‘é‡æœº':
        # SVMä½¿ç”¨æ ‡å‡†åŒ–æ•°æ®
        model.fit(X_train_scaled, y_train)
        y_pred_model = model.predict(X_test_scaled)
    else:
        # å…¶ä»–æ¨¡å‹ä½¿ç”¨åŸå§‹æ•°æ®
        model.fit(X_train, y_train)
        y_pred_model = model.predict(X_test)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    r2_model = r2_score(y_test, y_pred_model)
    mae_model = mean_absolute_error(y_test, y_pred_model)
    rmse_model = np.sqrt(mean_squared_error(y_test, y_pred_model))
    mape_model = np.mean(np.abs((y_test - y_pred_model) / y_test)) * 100
    
    model_results[name] = {
        'RÂ²': r2_model,
        'MAE': mae_model,
        'RMSE': rmse_model,
        'MAPE': mape_model
    }
    
    print(f"\nğŸ“ˆ {name}:")
    print(f"  RÂ²: {r2_model:.4f}")
    print(f"  MAE: {mae_model:.2f}")
    print(f"  RMSE: {rmse_model:.2f}")
    print(f"  MAPE: {mape_model:.2f}%")

# æ¨¡å‹æ¯”è¾ƒè¡¨æ ¼
print("\nğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¾ƒè¡¨ï¼š")
results_df = pd.DataFrame(model_results).T
print(results_df.round(4))

# æ‰¾å‡ºæœ€ä½³æ¨¡å‹
best_model_r2 = results_df['RÂ²'].idxmax()
best_model_mae = results_df['MAE'].idxmin()

print(f"\nğŸ† æœ€ä½³æ¨¡å‹ï¼ˆRÂ²ï¼‰: {best_model_r2} (RÂ² = {results_df.loc[best_model_r2, 'RÂ²']:.4f})")
print(f"ğŸ† æœ€ä½³æ¨¡å‹ï¼ˆMAEï¼‰: {best_model_mae} (MAE = {results_df.loc[best_model_mae, 'MAE']:.2f})")

# ğŸ”Ÿ ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆéšæœºæ£®æ—ï¼‰
print("\nğŸ¯ ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆéšæœºæ£®æ—ï¼‰ï¼š")
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

feature_importance = pd.DataFrame({
    'ç‰¹å¾': X.columns,
    'é‡è¦æ€§': rf_model.feature_importances_
}).sort_values('é‡è¦æ€§', ascending=False)

print(feature_importance)

# å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
fig_importance = go.Figure(data=[
    go.Bar(
        x=feature_importance['ç‰¹å¾'],
        y=feature_importance['é‡è¦æ€§'] * 100,
        marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'],
        text=[f'{imp:.2f}%' for imp in feature_importance['é‡è¦æ€§'] * 100],
        textposition='auto',
    )
])

fig_importance.update_layout(
    title='ğŸ¯ ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆéšæœºæ£®æ—ï¼‰',
    title_x=0.5,
    xaxis_title='ç‰¹å¾',
    yaxis_title='é‡è¦æ€§ (%)',
    height=500,
    width=800,
    showlegend=False
)

# ä¿å­˜å›¾è¡¨
fig_importance.write_html('/Users/zihao_/Documents/github/writing_log/certification/feature_importance.html')
fig_importance.write_image('/Users/zihao_/Documents/github/writing_log/certification/feature_importance.png', width=800, height=500)
fig_importance.show()

print("\nğŸ“Š ç‰¹å¾é‡è¦æ€§å›¾è¡¨å·²ä¿å­˜ä¸º 'feature_importance.html' å’Œ 'feature_importance.png'")

# 1ï¸âƒ£1ï¸âƒ£ äº¤å‰éªŒè¯åˆ†æ
from sklearn.model_selection import cross_val_score, KFold

print("\nğŸ”„ äº¤å‰éªŒè¯åˆ†æï¼ˆ5æŠ˜ï¼‰ï¼š")
print("="*60)

kfold = KFold(n_splits=5, shuffle=True, random_state=42)

cv_results = {}
for name, model in models.items():
    if name == 'æ”¯æŒå‘é‡æœº':
        # SVMä½¿ç”¨æ ‡å‡†åŒ–æ•°æ®
        X_scaled = scaler.fit_transform(X)
        cv_scores = cross_val_score(model, X_scaled, y, cv=kfold, scoring='r2')
    else:
        cv_scores = cross_val_score(model, X, y, cv=kfold, scoring='r2')
    
    cv_results[name] = cv_scores
    
    print(f"\nğŸ“ˆ {name}:")
    print(f"  å¹³å‡RÂ²: {cv_scores.mean():.4f} (Â±{cv_scores.std() * 2:.4f})")
    print(f"  å„æŠ˜RÂ²: {[f'{score:.4f}' for score in cv_scores]}")

# äº¤å‰éªŒè¯ç»“æœå¯è§†åŒ–
fig_cv = go.Figure()

for name, scores in cv_results.items():
    fig_cv.add_trace(go.Box(
        y=scores,
        name=name,
        boxpoints='all',
        jitter=0.3,
        pointpos=-1.8
    ))

fig_cv.update_layout(
    title='ğŸ”„ äº¤å‰éªŒè¯RÂ²åˆ†æ•°åˆ†å¸ƒ',
    title_x=0.5,
    xaxis_title='æ¨¡å‹',
    yaxis_title='RÂ²åˆ†æ•°',
    height=600,
    width=1000,
    showlegend=False
)

# ä¿å­˜å›¾è¡¨
fig_cv.write_html('/Users/zihao_/Documents/github/writing_log/certification/cross_validation.html')
fig_cv.write_image('/Users/zihao_/Documents/github/writing_log/certification/cross_validation.png', width=1000, height=600)
fig_cv.show()

print("\nğŸ“Š äº¤å‰éªŒè¯å›¾è¡¨å·²ä¿å­˜ä¸º 'cross_validation.html' å’Œ 'cross_validation.png'")

# 1ï¸âƒ£2ï¸âƒ£ å­¦ä¹ æ›²çº¿åˆ†æ
from sklearn.model_selection import learning_curve

print("\nğŸ“š å­¦ä¹ æ›²çº¿åˆ†æï¼š")

# é€‰æ‹©æœ€ä½³æ¨¡å‹è¿›è¡Œå­¦ä¹ æ›²çº¿åˆ†æ
best_model = RandomForestRegressor(n_estimators=100, random_state=42)

train_sizes, train_scores, val_scores = learning_curve(
    best_model, X, y, cv=5, n_jobs=-1, 
    train_sizes=np.linspace(0.1, 1.0, 10),
    scoring='r2'
)

# è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
val_mean = np.mean(val_scores, axis=1)
val_std = np.std(val_scores, axis=1)

# ç»˜åˆ¶å­¦ä¹ æ›²çº¿
fig_lc = go.Figure()

# æ·»åŠ è®­ç»ƒåˆ†æ•°
fig_lc.add_trace(go.Scatter(
    x=train_sizes,
    y=train_mean,
    mode='lines+markers',
    name='è®­ç»ƒåˆ†æ•°',
    line=dict(color='blue'),
    marker=dict(size=8)
))

# æ·»åŠ è®­ç»ƒåˆ†æ•°ç½®ä¿¡åŒºé—´
fig_lc.add_trace(go.Scatter(
    x=np.concatenate([train_sizes, train_sizes[::-1]]),
    y=np.concatenate([train_mean + train_std, (train_mean - train_std)[::-1]]),
    fill='toself',
    fillcolor='rgba(0,100,80,0.2)',
    line=dict(color='rgba(255,255,255,0)'),
    hoverinfo="skip",
    showlegend=False
))

# æ·»åŠ éªŒè¯åˆ†æ•°
fig_lc.add_trace(go.Scatter(
    x=train_sizes,
    y=val_mean,
    mode='lines+markers',
    name='éªŒè¯åˆ†æ•°',
    line=dict(color='red'),
    marker=dict(size=8)
))

# æ·»åŠ éªŒè¯åˆ†æ•°ç½®ä¿¡åŒºé—´
fig_lc.add_trace(go.Scatter(
    x=np.concatenate([train_sizes, train_sizes[::-1]]),
    y=np.concatenate([val_mean + val_std, (val_mean - val_std)[::-1]]),
    fill='toself',
    fillcolor='rgba(255,0,0,0.2)',
    line=dict(color='rgba(255,255,255,0)'),
    hoverinfo="skip",
    showlegend=False
))

fig_lc.update_layout(
    title='ğŸ“š å­¦ä¹ æ›²çº¿ï¼ˆéšæœºæ£®æ—ï¼‰',
    title_x=0.5,
    xaxis_title='è®­ç»ƒæ ·æœ¬æ•°',
    yaxis_title='RÂ²åˆ†æ•°',
    height=600,
    width=1000
)

# ä¿å­˜å›¾è¡¨
fig_lc.write_html('/Users/zihao_/Documents/github/writing_log/certification/learning_curve.html')
fig_lc.write_image('/Users/zihao_/Documents/github/writing_log/certification/learning_curve.png', width=1000, height=600)
fig_lc.show()

print("\nğŸ“Š å­¦ä¹ æ›²çº¿å›¾è¡¨å·²ä¿å­˜ä¸º 'learning_curve.html' å’Œ 'learning_curve.png'")

# 1ï¸âƒ£3ï¸âƒ£ é¢„æµ‹ç¤ºä¾‹
print("\nğŸ”® æ–°è½¦é”€é‡é¢„æµ‹ç¤ºä¾‹ï¼š")
print("="*60)

# åˆ›å»ºæ–°è½¦æ•°æ®ç¤ºä¾‹
new_cars = pd.DataFrame({
    'price': [200000, 300000, 150000],
    'horsepower': [150, 200, 120],
    'fuel_efficiency': [8.0, 10.0, 6.5],
    'brand_score': [85, 90, 75]
})

print("æ–°è½¦é…ç½®ï¼š")
print(new_cars)

# ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œé¢„æµ‹
best_rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
best_rf_model.fit(X, y)
predictions = best_rf_model.predict(new_cars)

print(f"\né¢„æµ‹æœˆé”€é‡ï¼š")
for i, pred in enumerate(predictions):
    print(f"  è½¦å‹{i+1}: {pred:.0f} è¾†/æœˆ")

print("\n" + "="*80)
print("ğŸ‰ æ±½è½¦é”€é‡é¢„æµ‹åˆ†æå®Œæˆï¼")
print("ğŸ“Š ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶ï¼š")
print("  - car_sales_analysis.html/.png: ç»¼åˆæ•°æ®åˆ†æ")
print("  - feature_importance.html/.png: ç‰¹å¾é‡è¦æ€§åˆ†æ")
print("  - cross_validation.html/.png: äº¤å‰éªŒè¯ç»“æœ")
print("  - learning_curve.html/.png: å­¦ä¹ æ›²çº¿åˆ†æ")
print("="*80)
